# Robots.txt for KreatorKart - Creator-Brand Collaboration Platform
# Website: https://vashitagupta.github.io/Web-Deveopment-Project/

# Allow all search engines to crawl the entire site
User-agent: *
Allow: /

# Specific directives for major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

# Disallow crawling of common administrative/sensitive directories
# (Add these if they exist in your project)
Disallow: /admin/
Disallow: /private/
Disallow: /temp/
Disallow: /cache/
Disallow: /logs/

# Allow crawling of CSS, JS, and image files for better indexing
Allow: /*.css
Allow: /*.js
Allow: /*.png
Allow: /*.jpg
Allow: /*.jpeg
Allow: /*.gif
Allow: /*.svg
Allow: /*.webp

# Crawl delay (optional - sets delay between requests in seconds)
Crawl-delay: 1

# Sitemap location (update this when you create a sitemap)
Sitemap: https://vashitagupta.github.io/Web-Deveopment-Project/sitemap.xml
